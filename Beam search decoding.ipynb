{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/variables/variables\n",
      "[5.7083338e-10 8.0145687e-02 1.0840950e-03 ... 7.3847808e-08 1.9917328e-08\n",
      " 1.1426140e-07]\n",
      "[1.6461930e-10 4.8376305e-04 1.7010428e-02 ... 3.0083536e-11 2.4172273e-09\n",
      " 4.4529544e-09]\n",
      "[1.1551909e-09 8.4229395e-02 3.1572168e-03 ... 1.4553136e-08 8.3187281e-08\n",
      " 1.6785401e-06]\n",
      "[3.7750111e-10 2.9806383e-02 7.7453523e-04 ... 1.7680976e-10 9.6733377e-09\n",
      " 4.2001653e-07]\n",
      "[1.4575246e-12 1.0309603e-05 2.0827657e-07 ... 6.9027547e-13 2.3165619e-12\n",
      " 1.0863002e-11]\n",
      "[2.3490374e-12 1.4520196e-04 4.8059641e-04 ... 4.5788742e-13 8.1868982e-12\n",
      " 1.3764800e-10]\n",
      "[2.8326782e-13 3.1409859e-06 4.9463492e-06 ... 5.7468177e-14 1.9066108e-10\n",
      " 8.4374209e-12]\n",
      "[5.9181432e-10 1.0900244e-02 1.2522967e-02 ... 1.3634367e-11 9.8378841e-08\n",
      " 2.6542508e-09]\n",
      "[4.6711985e-09 7.1613044e-03 5.1948622e-02 ... 2.0238755e-10 3.0558579e-07\n",
      " 9.1564672e-08]\n",
      "[3.2068231e-10 7.1658976e-02 4.7668251e-03 ... 5.8799103e-09 5.0448246e-08\n",
      " 2.7070968e-08]\n",
      "[6.5373890e-10 7.7871262e-04 2.9131782e-03 ... 5.9536315e-10 1.5349765e-07\n",
      " 1.2513570e-07]\n",
      "[6.1629291e-10 1.1158561e-03 3.1095278e-01 ... 1.5584346e-10 2.1128366e-07\n",
      " 2.1918248e-07]\n",
      "[2.91599278e-09 1.01821020e-03 1.01588186e-04 ... 5.01209962e-10\n",
      " 7.29718153e-08 5.84899666e-08]\n",
      "[2.90803959e-09 4.02692752e-03 9.90452152e-03 ... 6.31727204e-09\n",
      " 1.08456575e-07 1.22893357e-06]\n",
      "[2.1325077e-11 8.6071482e-03 1.0180756e-02 ... 2.4110867e-09 2.2440045e-09\n",
      " 1.2885626e-08]\n",
      "[1.3113236e-09 5.5624214e-03 6.1719898e-02 ... 2.2158109e-10 8.5260567e-08\n",
      " 4.0988385e-07]\n",
      "[2.5570684e-10 3.4463214e-04 2.3239698e-02 ... 5.6934815e-11 6.8779173e-08\n",
      " 2.2843446e-08]\n",
      "[8.2788019e-11 2.4912134e-02 3.7539951e-04 ... 3.0682601e-10 4.0134398e-09\n",
      " 3.3488996e-09]\n",
      "[7.0745423e-11 1.0062950e-03 4.0342283e-02 ... 4.1561608e-13 1.8859734e-09\n",
      " 8.6849272e-10]\n",
      "[6.28006980e-10 1.09366484e-01 4.41463524e-03 ... 9.19993137e-10\n",
      " 1.50210042e-07 5.79956122e-07]\n",
      "[2.40600956e-10 4.13740911e-02 1.23235711e-03 ... 1.41613075e-11\n",
      " 1.64674265e-08 1.67544442e-07]\n",
      "[3.3890328e-13 6.6699804e-06 1.4145147e-07 ... 2.0853983e-14 2.3222073e-12\n",
      " 4.4989828e-12]\n",
      "[1.3872542e-12 2.9387482e-04 1.1434793e-03 ... 6.0165685e-14 1.8652998e-11\n",
      " 1.0182031e-10]\n",
      "[1.13614034e-13 4.15457544e-06 6.62783350e-06 ... 3.38379519e-15\n",
      " 3.00836606e-10 4.95495051e-12]\n",
      "[8.1884236e-11 6.5912479e-03 8.2168216e-03 ... 2.3081691e-13 8.2340435e-08\n",
      " 6.0200023e-10]\n",
      "[6.7452016e-10 5.3965198e-03 4.3859005e-02 ... 3.4380584e-12 2.6916402e-07\n",
      " 2.1848901e-08]\n",
      "[5.3112886e-11 5.1136594e-02 8.8383874e-04 ... 6.2447304e-11 9.3775352e-09\n",
      " 6.9020429e-09]\n",
      "[1.04316104e-11 3.06967559e-04 8.85977875e-03 ... 1.94626318e-14\n",
      " 1.58165314e-09 2.80372614e-10]\n",
      "[2.3425992e-10 5.8891103e-02 1.9251782e-03 ... 1.0481509e-10 1.5492360e-07\n",
      " 4.4146674e-07]\n",
      "[1.1512353e-10 2.1260522e-02 6.2441372e-04 ... 1.8814191e-12 1.7094061e-08\n",
      " 1.3151728e-07]\n",
      "ธนาคาร เพื่อ ประชาชน ใน พื้นที่ จังหวัด ชาย แดน ภาค ใต้ และ รัฐบาล ที่ มี การ จัดตั้ง ศาลสิ่งแวดล้อม และ ให้ ประชาชน ใน พื้นที่ จังหวัด ชาย แดน ภาค ใต้ และ ประชาชน ใน พื้นที่ จังหวัด ชาย\n"
     ]
    }
   ],
   "source": [
    "from flask import request\n",
    "\n",
    "from tokenizer import SertisTokenizer\n",
    "import numpy as np\n",
    "from utils import savefile, loadfile\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "from keras.models import Sequential\n",
    "from qrnn import *\n",
    "\n",
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_second_best_idx(probs):\n",
    "    return np.arange(0, probs.shape[0])[np.argsort(probs) == probs.shape[0]-2][0]\n",
    "\n",
    "def create_model(max_sequence_len, total_words):\n",
    "    global MAX_LENGTH, words2idx\n",
    "    input_len = max_sequence_len - 1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 64, input_length=input_len))\n",
    "    \n",
    "    model.add(QRNN(256, window_size=2, dropout=0.1, return_sequences=True,\n",
    "               kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4), \n",
    "               kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10)))\n",
    "    model.add(QRNN(256, window_size=2, dropout=0.1, return_sequences=False,\n",
    "           kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4), \n",
    "           kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10)))\n",
    "    \n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_text(text, next_words, qrnn_model):\n",
    "    global MAX_LENGTH, words2idx, idx2word\n",
    "\n",
    "    for j in range(next_words):\n",
    "        token_list = [words2idx[w] for w in text.split()]\n",
    "        token_list = pad_sequences([token_list], maxlen=MAX_LENGTH-1, padding='pre')\n",
    "\n",
    "        predicted = np.squeeze(qrnn_model.predict(token_list, verbose=0))\n",
    "        print(predicted)\n",
    "        \n",
    "        output_word = idx2word[np.argmax(predicted)]\n",
    "        if output_word in text.split(' ')[-5:]:\n",
    "            output_word = idx2word[get_second_best_idx(predicted)]\n",
    "        \n",
    "        text += \" \" + output_word\n",
    "        \n",
    "    return text.strip()\n",
    "\n",
    "st = SertisTokenizer()\n",
    "MAX_LENGTH = 200\n",
    "words2idx = loadfile('words2idx.pkl')\n",
    "idx2word = loadfile('idx2word.pkl')\n",
    "qrnn_model = create_model(MAX_LENGTH, len(words2idx))\n",
    "qrnn_model.load_weights('QRNN_best.h5')\n",
    "print(generate_text('ธนาคาร เพื่อ ประชาชน', 30, qrnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = 'นายก ตัดสิน'; b = 3; h = 0; next_words = 40\n",
    "y = [[list(), 0] for i in range(b)] # for seq and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoding(test_text, states, model, b, h, next_words):\n",
    "    global MAX_LENGTH, words2idx, idx2word\n",
    "    if h == next_words:\n",
    "        return (' ').join([idx2word[w] for w in states[0][0]])\n",
    "    \n",
    "    else:\n",
    "        order = []\n",
    "        for s in states:\n",
    "            if len(s[0]) == 0: token_list = [words2idx[w] for w in test_text.split()]\n",
    "            else: token_list = s[0]\n",
    "            \n",
    "            distribution = np.squeeze(qrnn_model.predict(pad_sequences([token_list], maxlen=MAX_LENGTH-1, \n",
    "                                                                       padding='pre'), verbose=0))\n",
    "            for idx, p in enumerate(distribution):\n",
    "                if idx not in token_list[-3:]:\n",
    "                    order.append((s[1] - np.log(p), token_list + [idx]))\n",
    "\n",
    "        order = sorted(order)\n",
    "        if h != 0: \n",
    "            order = [(v, k) for (k, v) in order[:b]]\n",
    "        else:\n",
    "            new_order = []\n",
    "            s = set()\n",
    "            for (k, v) in order:\n",
    "                if v[0] not in s:\n",
    "                    new_order.append((v, k))\n",
    "                    if len(new_order) == b:\n",
    "                        break\n",
    "                    s.add(v[0])\n",
    "            order = new_order\n",
    "            \n",
    "        return beam_search_decoding(test_text, order, model, b, h+1, next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = beam_search_decoding(test_text, y, qrnn_model, b, h, next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'นายก ตัดสิน กล่าว ถึง กรณี ที่ มี การ ประชุม คณะ กรรมการ ใน การ ประชุม ครม ครั้ง นี้ ได้ รับ การ แต่งตั้ง คณะ กรรมการ บริหาร พรรค และ รัฐมนตรี ว่าการ กระทรวงพาณิชย์ ให้ สัมภาษณ์ ถึง กรณี ที่ พตททักษิณ ชินวัตร รักษาการ นายก รัฐมนตรี และ รมว ยุติธรรม เป็น'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [0]), (3, [0]), (5, [0]), (7, [0]), (9, [0])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [(5,[0]), (7,[0]), (9,[0]), (1,[0]), (3,[0])]\n",
    "sorted(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [0]), (3, [0]), (9, [0]), (7, [0]), (5, [0])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9a4cb8058b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheappush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "heapq.heappush(li,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (3, 1), (9, 1), (7, 1), (5, 1), 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ls + [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3025850929940455"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.907755278982137"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[1,3,3,4,4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
